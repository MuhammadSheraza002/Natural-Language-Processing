{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3bbc90c-96a6-41f8-a1b7-d5520d4ca6c5",
   "metadata": {},
   "source": [
    "---   \n",
    "<img align=\"left\" width=\"110\"   src=\"https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg\"> \n",
    "<h1 align=\"center\">Tools and Techniques for Data Science</h1>\n",
    "<h1 align=\"center\">Course: Natural Language Processing</h1>\n",
    "\n",
    "--- \n",
    "<h2><div align=\"right\">Muhammad Sheraz (Data Scientist)</div></h2>\n",
    "<h1 align=\"center\">Lecture 4: (Text Representation)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a7c01-e81c-4b2f-893b-6bc8549a086c",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"1100\"  src=\"../images/phase3.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37206d8-a956-4ec9-b4cf-642fdac9cabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7401bed6-feec-43c6-bce6-c06a7cc9760e",
   "metadata": {},
   "source": [
    "<div>\n",
    "\n",
    "</div>\n",
    "\n",
    "## Learning agenda of this notebook\n",
    "\n",
    "1. **Feature Extraction**\n",
    "    - Label Encoding\n",
    "    - One Hot Encoding   \n",
    "    - Bag of Words (BoW) Representation\n",
    "    - Creating Bag of N-grams\n",
    "    - Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7be4b9-d04f-4e4e-ba11-3d6e2c821c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b244e4-feaa-4346-adf8-20135447ad8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad3db157-2527-414d-a778-041b9d51018e",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20101b5-8c3e-45a7-aa84-b1303fdccef4",
   "metadata": {},
   "source": [
    "<img    src='images/Text Representation.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7fc8b-695f-4fe1-b5fb-587940c6317f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25bd3c-f33d-47e4-adb3-ad1429405d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b21de-9fd4-4c5f-b2b0-fe021b9a6126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c20465-eb64-45bf-8b7f-747a24f1c400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3415d7-6a74-4da9-8e48-28a2fb7e6795",
   "metadata": {},
   "source": [
    "## Label Encoding\r\n",
    "\r\n",
    "- **Definition:**\r\n",
    "  - Label encoding is a technique used in natural language processing (NLP) to assign numerical labels to categorical variables. It is commonly applied to represent text data, such as unique words in a vocabulary, as numerical values.\r\n",
    "\r\n",
    "- **Process:**\r\n",
    "  - Assign a unique numerical label to each category (word) in the dataset.\r\n",
    "  - Labels are typically assigned in ascending order starting from 0.\r\n",
    "\r\n",
    "- **Key Components:**\r\n",
    "  - **Encoded Labels:** The set of unique words across all documents mapped to numerical labels.\r\n",
    "\r\n",
    "- **Pros:**\r\n",
    "  - Simple and straightforward method to represent categorical variables as numerical values.\r\n",
    "  - Compatible with various machine learning algorithms.\r\n",
    "\r\n",
    "- **Cons:**\r\n",
    "  - Does not capture any inherent ordinal relationships between categories.\r\n",
    "  - May introduce unintended ordinality in certain algorithms.\r\n",
    "\r\n",
    "- **Use Cases:**\r\n",
    "  - Commonly used in preprocessing text data for machine learning tasks such as classification and regression.\r\n",
    "  - Suitable for scenarios where nominal categories need to be represented numerically.\r\n",
    "\r\n",
    "- **Libraries:**\r\n",
    "  - Python libraries like scikit-learn provide tools (e.g., `LabelEncoder`) for easy implementation of label encoding.\r\n",
    "\r\n",
    "- **Considerations:**\r\n",
    "  - Ensure that label encoding is appropriate for the specific task and dataset.\r\n",
    "  - Handle unseen categories gracefully, either by ignoring them or assigning a special label.\r\n",
    "\r\n",
    "### Encoded Labels:\r\n",
    "\r\n",
    "- Vocabulary Label Encoding:\r\n",
    "  - Muhammad: 0\r\n",
    "  - Sheraz: 1\r\n",
    "  - is: 2\r\n",
    "  - a: 3\r\n",
    "  - Student: 4\r\n",
    "  - of: 5\r\n",
    "  - Data: 6\r\n",
    "  - Science: 7\r\n",
    "  - He: 8\r\n",
    "  - Learning: 9\r\n",
    "  - Natural: 10\r\n",
    "  - Language: 11\r\n",
    "  - Processing: 12\r\n",
    "  - very: 13\r\n",
    "  - good: 14\r\n",
    "  - in: 15\r\n",
    "  - Machine: 16\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "196e166f-32ba-4b04-971f-eb26e7f73553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 1 2 3 4 5 6 7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 2 9 10 11 12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 2 13 14 15 16 9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Text  Output\n",
       "0    0 1 2 3 4 5 6 7       1\n",
       "1     8 2 9 10 11 12       0\n",
       "2  8 2 13 14 15 16 9       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the vocabulary label encoding\n",
    "label_encoding = {\n",
    "    'Muhammad': 0,\n",
    "    'Sheraz': 1,\n",
    "    'is': 2,\n",
    "    'a': 3,\n",
    "    'Student': 4,\n",
    "    'of': 5,\n",
    "    'Data': 6,\n",
    "    'Science': 7,\n",
    "    'He': 8,\n",
    "    'Learning': 9,\n",
    "    'Natural': 10,\n",
    "    'Language': 11,\n",
    "    'Processing': 12,\n",
    "    'very': 13,\n",
    "    'good': 14,\n",
    "    'in': 15,\n",
    "    'Machine': 16\n",
    "}\n",
    "\n",
    "# Sample dataframe\n",
    "data = {'Text': ['Muhammad Sheraz is a Student of Data Science',\n",
    "                  'He is Learning Natural Language Processing',\n",
    "                  'He is very good in Machine Learning'],\n",
    "        'Output': [1, 0, 1]}  # Adding a binary output column\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply label encoding to the text column\n",
    "encoded_text = df['Text'].apply(lambda x: ' '.join(str(label_encoding.get(word, word)) for word in x.split()))\n",
    "\n",
    "# Combine the encoded text with the output column\n",
    "encoded_df = pd.DataFrame({'Text': encoded_text, 'Output': df['Output']})\n",
    "\n",
    "encoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a948a4fd-4ce1-425b-a83e-b0c9aedb78ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Muhammad Sheraz is a Student of Data Science.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is Learning Natural Language Processing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is very good in Machine Learning.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text  Output\n",
       "0  \"Muhammad Sheraz is a Student of Data Science.\"       1\n",
       "1      He is Learning Natural Language Processing.       0\n",
       "2             He is very good in Machine Learning.       1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a sample dataframe\n",
    "data = {'Text': ['\"Muhammad Sheraz is a Student of Data Science.\"',\n",
    "                 'He is Learning Natural Language Processing.',\n",
    "                 'He is very good in Machine Learning.'],\n",
    "        'Output': [1, 0, 1]}  # Adding a binary output column\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ded5c46-df91-4a0d-867d-176dc4d59a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>good</th>\n",
       "      <th>he</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>muhammad</th>\n",
       "      <th>natural</th>\n",
       "      <th>of</th>\n",
       "      <th>processing</th>\n",
       "      <th>science</th>\n",
       "      <th>sheraz</th>\n",
       "      <th>student</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  good  he  in  is  language  learning  machine  muhammad  natural  of  \\\n",
       "0     1     0   0   0   0         0         0        0         1        0   1   \n",
       "1     0     0   1   0   0         1         1        0         0        1   0   \n",
       "2     0     1   1   1   0         0         1        1         0        0   0   \n",
       "\n",
       "   processing  science  sheraz  student  very  \n",
       "0           0        1       1        1     0  \n",
       "1           1        0       0        0     0  \n",
       "2           0        0       0        0     1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tokenization using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Convert sparse matrix to DataFrame\n",
    "dtm_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Apply label encoding to each column\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_df = dtm_df.apply(label_encoder.fit_transform)\n",
    "\n",
    "# Combine the encoded DataFrame with the output column\n",
    "#encoded_df['Output'] = df['Output']\n",
    "\n",
    "encoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3ce31-a4e9-4e5b-99b3-82a704cf0bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04b1f0-59ea-45bd-96d4-750e02be127e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "625a5eee-ce6b-4f97-b6e6-3f29b35ffd8c",
   "metadata": {},
   "source": [
    "## One-Hot Encoding Representation\n",
    "\n",
    "- **Definition:**\n",
    "  - One-hot encoding is a technique used in natural language processing (NLP) to represent categorical variables as binary vectors.\n",
    "  - It creates a binary vector where each element corresponds to a unique word in the vocabulary, indicating its presence or absence in a document.\n",
    "\n",
    "- **Process:**\n",
    "  - **Tokenization:** Breaks text into individual words or tokens.\n",
    "  - **Lowercasing:** Converts all words to lowercase to ensure uniformity.\n",
    "  - **Vocabulary Creation:** Build a vocabulary of unique words across all documents.\n",
    "  - **One-Hot Encoding:** Represent each document as a binary vector, where each element corresponds to a word in the vocabulary. If a word is present in the document, its corresponding element is set to 1; otherwise, it's set to 0.\n",
    "\n",
    "- **Key Components:**\n",
    "  - **Binary Document-Term Matrix:** The resulting matrix where each row represents a document, and each column represents a unique word, with binary values indicating word presence or absence.\n",
    "  - **Vocabulary:** The set of unique words across all documents.\n",
    "\n",
    "- **Pros:**\n",
    "  - Maintains the vocabulary size without increasing dimensionality further.\n",
    "  - Preserves word order and semantics.\n",
    "\n",
    "- **Cons:**\n",
    "  - Results in high-dimensional sparse matrices, especially with large vocabularies.\n",
    "\n",
    "- **Use Cases:**\n",
    "  - Useful when word presence is more important than word frequency.\n",
    "  - Commonly used in text classification and neural network-based models.\n",
    "\n",
    "- **Libraries:**\n",
    "  - Libraries like scikit-learn in Python provide tools for implementing one-hot encoding.\n",
    "\n",
    "- **Considerations:**\n",
    "  - Suitable for scenarios where each word is considered independent of others.\n",
    "  - May require additional techniques like dimensionality reduction for handling large vocabularies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0b55b-30fb-42fc-b959-6bd5af925107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e46939-31f8-4b84-99ec-879ae30693bb",
   "metadata": {},
   "source": [
    "<img src='images/ohe1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142533c-e6ed-4380-8807-666707620e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bacaf-aeaf-475e-99fd-91f985a31d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70064dd9-a5c7-4026-a520-b855bf5ad8ef",
   "metadata": {},
   "source": [
    "### One-Hot Encoding Example\n",
    "\n",
    "Consider a corpus with three documents:\n",
    "\n",
    "1. **Document 1**: \"Muhammad Sheraz is a Student of Data Science.\"\n",
    "2. **Document 2**: \"He is Learning Natural Language Processing.\"\n",
    "3. **Document 3**: \"He is very good in Machine Learning.\"\n",
    "\n",
    "#### Step 1: Tokenization\n",
    "\n",
    "- Unique words across all documents:\n",
    "  - {Muhammad, Sheraz, is, a, Student, of, Data, Science, He, Learning, Natural, Language, Processing, very, good, in, Machine}\n",
    "\n",
    "#### Step 2: One-Hot Encoding\n",
    "\n",
    "- Represent each word as a binary vector indicating its presence in each document:\n",
    "\n",
    "| Word       | Document 1 | Document 2 | Document 3 |\n",
    "|------------|------------|------------|------------|\n",
    "| Muhammad   | 1          | 0          | 0          |\n",
    "| Sheraz     | 1          | 0          | 0          |\n",
    "| is         | 1          | 1          | 1          |\n",
    "| a          | 1          | 0          | 0          |\n",
    "| Student    | 1          | 0          | 0          |\n",
    "| of         | 1          | 0          | 0          |\n",
    "| Data       | 1          | 0          | 0          |\n",
    "| Science    | 1          | 0          | 0          |\n",
    "| He         | 0          | 1          | 1          |\n",
    "| Learning   | 0          | 1          | 0          |\n",
    "| Natural    | 0          | 1          | 0          |\n",
    "| Language   | 0          | 1          | 0          |\n",
    "| Processing | 0          | 1          | 0          |\n",
    "| very       | 0          | 0          | 1          |\n",
    "| good       | 0          | 0          | 1          |\n",
    "| in         | 0          | 0          | 1          |\n",
    "| Machine    | 0          | 0          | 1          |\n",
    "\n",
    "The one-hot encoded representation captures the presence of each word in each document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f035872-6231-45d6-8b44-94b516a9e978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930e38e-4a48-4364-9795-7c593dea0222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb509b9-39a5-4327-b387-097ba45fb48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "267eed77-1a28-45a0-8737-553fa5961df3",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW) Representation\r\n",
    "\r\n",
    "- **Definition:**\r\n",
    "  - BoW is a common technique in natural language processing (NLP) to represent text data as a numerical matrix.\r\n",
    "  - It focuses on the occurrence and frequency of words in a document, disregarding grammar and word order.\r\n",
    "\r\n",
    "- **Process:**\r\n",
    "  - **Tokenization:** Breaks text into individual words or tokens.\r\n",
    "  - **Lowercasing:** Converts all words to lowercase to ensure uniformity.\r\n",
    "  - **Stopword Removal:** Eliminates common words (e.g., 'the', 'is') that add little meaning.\r\n",
    "  - **Counting:** Creates a matrix where each row represents a document, and each column represents a unique word, counting the occurrences.\r\n",
    "\r\n",
    "- **Key Components:**\r\n",
    "  - **Document-Term Matrix (DTM):** The resulting matrix showing the frequency of each word in each document.\r\n",
    "  - **Vocabulary:** The set of unique words across all documents.\r\n",
    "\r\n",
    "- **Pr,initutiveos:**\r\n",
    "  - Simple and computationally efficient.\r\n",
    "  - Captures important term frequencies for basic text anal\n",
    "  - Sparcity ysis.\r\n",
    "\r\n",
    "- **Cons:**\r\n",
    "  - Ignores word order and semantics.\r\n",
    "  - Doesn't consider relationships between words (e.g., 'good' and 'great' are treated as separate entities).\r\n",
    "\r\n",
    "- **Use Cases:**\r\n",
    "  - Commonly used in text classification, sentiment analysis, and information retrieval.\r\n",
    "  - Foundation for more advanced NLP techniques like TF-IDF and word embeddings.\r\n",
    "\r\n",
    "- **Libraries:**\r\n",
    "  - Popular libraries like scikit-learn in Python provide tools (e.g., `CountVectorizer`) for easy implementation.\r\n",
    "\r\n",
    "- **Considerations:**\r\n",
    "  - Customize preprocessing steps and hyperparameters based on specific needs.\r\n",
    "  - May require additional techniques for handling large vocabularies or improving semantic understanding.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6660906-7881-4316-bc94-8385d69bff9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cf9933a-137e-4532-8089-67c0b53b273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoded Matrix:\n",
      "[[1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0]\n",
      " [0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0]\n",
      " [0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "Vocabulary:\n",
      "['data' 'good' 'he' 'in' 'is' 'language' 'learning' 'machine' 'muhammad'\n",
      " 'natural' 'of' 'processing' 'science' 'sheraz' 'student' 'very']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the corpus\n",
    "corpus = [\n",
    "    \"Muhammad Sheraz is a Student of Data Science.\",\n",
    "    \"He is Learning Natural Language Processing.\",\n",
    "    \"He is very good in Machine Learning.\"\n",
    "]\n",
    "\n",
    "# Initialize CountVectorizer for one-hot encoding\n",
    "vectorizer = CountVectorizer(binary=False)\n",
    "\n",
    "# Fit the vectorizer on the corpus\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the corpus into a one-hot encoded matrix\n",
    "one_hot_encoded_matrix = vectorizer.transform(corpus).toarray()\n",
    "\n",
    "# Get the vocabulary (unique words) and their respective indices\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the one-hot encoded matrix and vocabulary\n",
    "print(\"One-Hot Encoded Matrix:\")\n",
    "print(one_hot_encoded_matrix)\n",
    "print(\"\\nVocabulary:\")\n",
    "print(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff37f8-9c6f-456a-b4a9-03ddefdce172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf827ca-e211-45eb-8804-62efbb466431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c3ed8-8aab-406c-bc2d-fe38b70f25cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fe1595c-dd14-4b97-b8a7-d789b0c01ad1",
   "metadata": {},
   "source": [
    "### Bag of Words (BoW) Example\r\n",
    "\r\n",
    "Consider a corpus with three documents:\r\n",
    "\r\n",
    "1. Document 1: \"Muhammad Sheraz is a Student of Data Science.\"\r\n",
    "2. Document 2: \"He is Learning Natural Language Processing.\"\r\n",
    "3. Document 3: \"He is very good in Machine Learning.\"\r\n",
    "\r\n",
    "#### Step 1: Tokenization\r\n",
    "\r\n",
    "- Unique words across all documents:\r\n",
    "  - {Muhammad, Sheraz, is, a, Student, of, Data, Science, He, Learning, Natural, Language, Processing, very, good, in, Machine}\r\n",
    "\r\n",
    "#### Step 2: Create Vocabulary\r\n",
    "\r\n",
    "- Assign an index to each unique word:\r\n",
    "  - Vocabulary: {Muhammad: 0, Sheraz: 1, is: 2, a: 3, Student: 4, of: 5, Data: 6, Science: 7, He: 8, Learning: 9, Natural: 10, Language: 11, Processing: 12, very: 13, good: 14, in: 15, Machine: 16}\r\n",
    "\r\n",
    "#### Step 3: Document-Term Matrix (DTM)\r\n",
    "\r\n",
    "- Represent each document as a vector of word frequencies based on the vocabulary:\r\n",
    "\r\n",
    "| Document | Muhammad | Sheraz | is | a | Student | of | Data | Science | He | Learning | Natural | Language | Processing | very | good | in | Machine |\r\n",
    "|----------|----------|--------|----|---|---------|----|------|---------|----|----------|---------|----------|------------|------|------|----|---------|\r\n",
    "| 1        | 1        | 1      | 1  | 1 | 1       | 1  | 1    | 1       | 0  | 0        | 0       | 0        | 0          | 0    | 0    | 0  | 0       |\r\n",
    "| 2        | 0        | 0      | 1  | 0 | 0       | 0  | 0    | 0       | 1  | 1        | 1       | 1        | 1          | 0    | 0    | 0  | 0       |\r\n",
    "| 3        | 0        | 0      | 1  | 0 | 0       | 0  | 0    | 0       | 1  | 0        | 0       | 0        | 0          | 1    | 1    | 1  | 1       |\r\n",
    "\r\n",
    "The Document-Term Matrix (DTM) captures the frequency of each word in each document, forming the basis of the Bag of Words (BoW) representation.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e85a6-e56b-4d8a-a48d-a294b1137c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110edaab-cc2b-463e-ac13-d06403494632",
   "metadata": {},
   "outputs": [],
   "source": [
    "Document 1: \n",
    "2. Document 2: \"\"\n",
    "3. Document 3: \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa246e3-8dc5-45a3-b8c0-4ad88c570649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Muhammad Sheraz is a Student of Data Science.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is Learning Natural Language Processing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is very good in Machine Learning.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text  Output\n",
       "0  \"Muhammad Sheraz is a Student of Data Science.\"       1\n",
       "1      He is Learning Natural Language Processing.       0\n",
       "2             He is very good in Machine Learning.       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a sample dataframe\n",
    "data = {'Text': ['\"Muhammad Sheraz is a Student of Data Science.\"',\n",
    "                 'He is Learning Natural Language Processing.',\n",
    "                 'He is very good in Machine Learning.'],\n",
    "        'Output': [1, 0, 1]}  # Adding a binary output column\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e3ef6-aeb3-41ce-8955-5bd08d99d6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6df5eaa-996f-4b50-a6af-a188ae483fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>good</th>\n",
       "      <th>he</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>muhammad</th>\n",
       "      <th>natural</th>\n",
       "      <th>of</th>\n",
       "      <th>processing</th>\n",
       "      <th>science</th>\n",
       "      <th>sheraz</th>\n",
       "      <th>student</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  good  he  in  is  language  learning  machine  muhammad  natural  of  \\\n",
       "0     1     0   0   0   1         0         0        0         1        0   1   \n",
       "1     0     0   1   0   1         1         1        0         0        1   0   \n",
       "2     0     1   1   1   1         0         1        1         0        0   0   \n",
       "\n",
       "   processing  science  sheraz  student  very  \n",
       "0           0        1       1        1     0  \n",
       "1           1        0       0        0     0  \n",
       "2           0        0       0        0     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply bag-of-words representation with specified hyperparameters\n",
    "vectorizer = CountVectorizer(\n",
    "    lowercase=True,      # Convert all characters to lowercase\n",
    "    #stop_words='english', # Remove common English stop words\n",
    "    max_features=None,    # Keep all unique words (no limit on features)\n",
    "    binary=False,         # Count occurrences (binary=False) or presence (binary=True)\n",
    "    ngram_range=(1, 1)    # Use unigrams (single words), can be adjusted for bigrams, trigrams, etc.\n",
    ")\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Convert the bag-of-words matrix to a DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0097d53c-3103-439f-a1ca-9eff84f8e109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [0, 2, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 1, 1, 0, 1, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb26421-aa95-4050-97df-a9e1565e4372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbbd621-5696-4e38-80e0-8c8d637c89c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix[3].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646f44db-e991-4448-96a5-b4ae6c2283d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['document is the final document']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bb593-0b27-43b0-ac07-baf87bcb9968",
   "metadata": {},
   "source": [
    "## Understanding `vectorizer.vocabulary_` in `CountVectorizer`\n",
    "\n",
    "In the scikit-learn `CountVectorizer` class, `vectorizer.vocabulary_` is an attribute that provides a mapping between terms (words) and their indices in the bag-of-words matrix. Here's how it works:\n",
    "\n",
    "### Vocabulary Building Process\n",
    "\n",
    "1. **Tokenization:**\n",
    "   - The text data is tokenized, breaking it into individual words or tokens.\n",
    "\n",
    "2. **Lowercasing:**\n",
    "   - All words are converted to lowercase to ensure consistency.\n",
    "\n",
    "3. **Stopword Removal (if specified):**\n",
    "   - Common English stop words (e.g., 'the', 'is', 'and') may be removed based on the `stop_words` parameter.\n",
    "\n",
    "4. **Building the Vocabulary:**\n",
    "   - For each unique word in the preprocessed text data, a unique index is assigned.\n",
    "   - The resulting vocabulary is stored in a dictionary, where the keys are the words, and the values are their corresponding indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f7a09-64f6-44e2-8cc4-ce6d8b6c10b1",
   "metadata": {},
   "source": [
    "### Text data:\r\n",
    "\n",
    "1. \"Muhammad Sheraz is a Student of Data Science.\"\r\n",
    "2. \"He is Learning Natural Language Processing.\"\r\n",
    "3. \"He is very good in Machine Learning.\"\r\n",
    "\r\n",
    "After tokenization, lowercasing, and stopword removal, we get a set of unique words:\r\n",
    "{'muhammad', 'sheraz', 'student', 'data', 'science', 'learning', 'natural', 'language', 'processing', 'good', 'machine'}\r\n",
    "\r\n",
    "The vocabulary dictionary:\r\n",
    "{\r\n",
    " 'muhammad': 0,\r\n",
    " 'sheraz': 1,\r\n",
    " 'student': 2,\r\n",
    " 'data': 3,\r\n",
    " 'science': 4,\r\n",
    " 'learning': 5,\r\n",
    " 'natural': 6,\r\n",
    " 'language': 7,\r\n",
    " 'processing': 8,\r\n",
    " 'good': 9,\r\n",
    " 'machine': 10\r\n",
    "}\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb564a-f144-42be-a6fd-3f6d89f935fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a420b8-233d-49d7-bda1-40111b4989a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbec6b42-18fa-4ef5-9c73-7e18c3acd4e4",
   "metadata": {},
   "source": [
    "## Example of Vocabulary Building in Bag-of-Words (BoW)\n",
    "\n",
    "Consider the following text data:\n",
    "\n",
    "1. Document 1: \"Muhammad Sheraz is a Student of Data Science.\"\n",
    "2. Document 2: \"He is Learning Natural Language Processing.\"\n",
    "3. Document 3: \"He is very good in Machine Learning.\"\n",
    "\n",
    "### Step 1: Tokenization\n",
    "\n",
    "Tokenize the text into individual words:\n",
    "\n",
    "1. Document 1: [\"Muhammad\", \"Sheraz\", \"is\", \"a\", \"Student\", \"of\", \"Data\", \"Science.\"]\n",
    "2. Document 2: [\"He\", \"is\", \"Learning\", \"Natural\", \"Language\", \"Processing.\"]\n",
    "3. Document 3: [\"He\", \"is\", \"very\", \"good\", \"in\", \"Machine\", \"Learning.\"]\n",
    "\n",
    "### Step 2: Lowercasing\n",
    "\n",
    "Convert all words to lowercase:\n",
    "\n",
    "1. Document 1: [\"muhammad\", \"sheraz\", \"is\", \"a\", \"student\", \"of\", \"data\", \"science.\"]\n",
    "2. Document 2: [\"he\", \"is\", \"learning\", \"natural\", \"language\", \"processing.\"]\n",
    "3. Document 3: [\"he\", \"is\", \"very\", \"good\", \"in\", \"machine\", \"learning.\"]\n",
    "\n",
    "### Step 3: Vocabulary Building\n",
    "\n",
    "Build the vocabulary by assigning unique indices to each unique word:\n",
    "\n",
    "```markdown\n",
    "{\n",
    " 'muhammad': 0,\n",
    " 'sheraz': 1,\n",
    " 'is': 2,\n",
    " 'a': 3,\n",
    " 'student': 4,\n",
    " 'of': 5,\n",
    " 'data': 6,\n",
    " 'science': 7,\n",
    " 'he': 8,\n",
    " 'learning': 9,\n",
    " 'natural': 10,\n",
    " 'language': 11,\n",
    " 'processing': 12,\n",
    " 'very': 13,\n",
    " 'good': 14,\n",
    " 'in': 15,\n",
    " 'machine': 16\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e22b9-1526-4004-a903-58ae674707d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b4969-6222-4712-82dd-3df4df0b0376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f8760-3e90-4c52-ba74-c65cb186c3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169dc595-7962-4a81-8cf3-5b9fdddebcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'muhammad': 8,\n",
       " 'sheraz': 13,\n",
       " 'is': 4,\n",
       " 'student': 14,\n",
       " 'of': 10,\n",
       " 'data': 0,\n",
       " 'science': 12,\n",
       " 'he': 2,\n",
       " 'learning': 6,\n",
       " 'natural': 9,\n",
       " 'language': 5,\n",
       " 'processing': 11,\n",
       " 'very': 15,\n",
       " 'good': 1,\n",
       " 'in': 3,\n",
       " 'machine': 7}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8155c-42a8-476c-8eb1-21d15847ba44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cfb45-c951-4aa8-8d89-448fc4fb4a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be15c3e2-8ff3-421d-b265-639c8c4e3059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "      <th>data</th>\n",
       "      <th>good</th>\n",
       "      <th>he</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>muhammad</th>\n",
       "      <th>natural</th>\n",
       "      <th>of</th>\n",
       "      <th>processing</th>\n",
       "      <th>science</th>\n",
       "      <th>sheraz</th>\n",
       "      <th>student</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Muhammad Sheraz is a Student of Data Science.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is Learning Natural Language Processing.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is very good in Machine Learning.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text  Output  data  good  he  \\\n",
       "0  \"Muhammad Sheraz is a Student of Data Science.\"       1     1     0   0   \n",
       "1      He is Learning Natural Language Processing.       0     0     0   1   \n",
       "2             He is very good in Machine Learning.       1     0     1   1   \n",
       "\n",
       "   in  is  language  learning  machine  muhammad  natural  of  processing  \\\n",
       "0   0   1         0         0        0         1        0   1           0   \n",
       "1   0   1         1         1        0         0        1   0           1   \n",
       "2   1   1         0         1        1         0        0   0           0   \n",
       "\n",
       "   science  sheraz  student  very  \n",
       "0        1       1        1     0  \n",
       "1        0       0        0     0  \n",
       "2        0       0        0     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat([df, bow_df], axis=1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea7d73-6a27-4af8-9867-453fce07573d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e27892-d636-43c2-8cc7-069926003a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d7d87-398b-4058-afdc-344f76d16f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa3bdc-165b-4854-9047-3d7567ac6a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f87838ca-09d2-4317-be82-4f8adac46c69",
   "metadata": {},
   "source": [
    "## CountVectorizer Hyperparameters\r\n",
    "\r\n",
    "- **`lowercase` (default=True):**\r\n",
    "  - *Description:* Converts all text to lowercase. Helps in treating words with different cases as the same.\r\n",
    "  - *Default Value:* True\r\n",
    "  - *Use Case:* Set to False if you want to preserve the case sensitivity of words.\r\n",
    "\r\n",
    "- **`stop_words` (default=None):**\r\n",
    "  - *Description:* Removes common English stop words (e.g., 'the', 'is', 'and') to focus on more meaningful words.\r\n",
    "  - *Default Value:* None\r\n",
    "  - *Use Case:* Pass 'english' to remove common English stop words. Custom stop words can be provided as a list.\r\n",
    "\r\n",
    "- **`max_features` (default=None):**\r\n",
    "  - *Description:* Limits the number of unique words to consider. If specified, the most frequent words are selected.\r\n",
    "  - *Default Value:* None\r\n",
    "  - *Use Case:* Set a specific number to limit the vocabulary size, helpful when dealing with large datasets or when focusing on top words.\r\n",
    "\r\n",
    "- **`binary` (default=False):**\r\n",
    "  - *Description:* If True, the matrix representation is binary (1 if the word is present, 0 if not). If False, it counts the occurrences.\r\n",
    "  - *Default Value:* False\r\n",
    "  - *Use Case:* Set to True for binary representation when only presence/absence matters, not the frequency.\r\n",
    "\r\n",
    "- **`ngram_range` (default=(1, 1)):**\r\n",
    "  - *Description:* Specifies the range of n-grams to consider. For example, (1, 1) considers only unigrams, (1, 2) considers unigrams and bigrams, etc.\r\n",
    "  - *Default Value:* (1, 1)\r\n",
    "  - *Use Case:* Adjust to capture more context by including bigrams (or trigrams) in addition to unigrams.\r\n",
    "\r\n",
    "- **`tokenizer` (default=None):**\r\n",
    "  - *Description:* Custom function for tokenization. If None, it uses the default tokenizer.\r\n",
    "  - *Default Value:* None\r\n",
    "  - *Use Case:* Provide a custom tokenizer function if the default tokenization is not suitable for your data.\r\n",
    "\r\n",
    "- **`preprocessor` (default=None):**\r\n",
    "  - *Description:* Custom function applied to each document before tokenization and stop word removal.\r\n",
    "  - *Default Value:* None\r\n",
    "  - *Use Case:* Use when additional preprocessing is required before tokenization.\r\n",
    "\r\n",
    "- **`max_df` (default=1.0):**\r\n",
    "  - *Description:* Ignores terms that have a document frequency strictly higher than the specified threshold (float or integer).\r\n",
    "  - *Default Value:* 1.0\r\n",
    "  - *Use Case:* Exclude words that are too common and may not provide meaningful information.\r\n",
    "\r\n",
    "- **`min_df` (default=1):**\r\n",
    "  - *Description:* Ignores terms that have a document frequency strictly lower than the specified threshold (float or integer).\r\n",
    "  - *Default Value:* 1\r\n",
    "  - *Use Case:* Exclude words that are too rare and may not contribute much to the analysis.\r\n",
    "\r\n",
    "- **`vocabulary` (default=None):**\r\n",
    "  - *Description:* List of words to consider. If not None, it ignores all terms that are not in this list.\r\n",
    "  - *Default Value:* None\r\n",
    "  - *Use Case:* Provide a custom vocabulary list to restrict the features to a predefined set.\r\n",
    "\r\n",
    "- **`strip_accents` (default=None):**\r\n",
    "  - *Description:* Remove accents during the preprocessing step.\r\n",
    "  - *Default Value:* None\r\n",
    "  - *Use Case:* Set to 'ascii' or 'unicode' to remove accents from words.\r\n",
    "\r\n",
    "- **`token_pattern` (default=r\"(?u)\\b\\w\\w+\\b\"):**\r\n",
    "  - *Description:* Regular expression defining what constitutes a 'word' and how to split it.\r\n",
    "  - *Default Value:* r\"(?u)\\b\\w\\w+\\b\"\r\n",
    "  - *Use Case:* Customize the pattern to suit specific tokenization requirements.\r\n",
    "\r\n",
    "- **`analyzer` (default='word'):**\r\n",
    "  - *Description:* Determines whether the feature should be made of word n-gram or character n-grams.\r\n",
    "  - *Default Value:* 'word'\r\n",
    "  - *Use Case:* Set to 'char' or 'char_wb' for character n-grams instead of word n-grams.\r\n",
    "\r\n",
    "- **`dtype` (default=np.int64):**\r\n",
    "  - *Description:* Type of the matrix returned.\r\n",
    "  - *Default Value:* np.int64\r\n",
    "  - *Use Case:* Adjust if a different data type for the matrix is required.\r\n",
    "\r\n",
    "- **`input` (default='content'):**\r\n",
    "  - *Description:* 'content' interprets input as a collection of raw text documents.\r\n",
    "  - *Default Value:* 'content'\r\n",
    "  - *Use Case:* Typically, there's no need to change this unless the input format is different.\r\n",
    "\r\n",
    "These hyperparameters offer flexibility in customizing the behavior of the `CountVectorizer` based on specific requirements and characteristics of the input text data. Adjusting these hyperparameters allows for fine-tuning the Bag of Words representation.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590c8e9-9307-4261-978b-b832b790b682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58115cb8-5031-4e57-82e1-7bf26c60e682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed2f4c3d-58c9-4ed1-8cb6-648d4f3fdc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the first book about a thrilling adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book2 is a non-fiction work by AuthorB.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The third book is a fictional story by AuthorA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AuthorC wrote a mystery novel in Book4.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  This is the first book about a thrilling adven...\n",
       "1            Book2 is a non-fiction work by AuthorB.\n",
       "2    The third book is a fictional story by AuthorA.\n",
       "3            AuthorC wrote a mystery novel in Book4."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create an advanced sample dataframe\n",
    "data = {\n",
    "        'Text': ['This is the first book about a thrilling adventure.',\n",
    "                 'Book2 is a non-fiction work by AuthorB.',\n",
    "                 'The third book is a fictional story by AuthorA.',\n",
    "                 'AuthorC wrote a mystery novel in Book4.']}\n",
    "df_advanced = pd.DataFrame(data)\n",
    "\n",
    "# Display the advanced sample dataframe\n",
    "df_advanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d032e083-3b2e-4a0f-92fa-463158e2257a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adventure</th>\n",
       "      <th>authora</th>\n",
       "      <th>authorb</th>\n",
       "      <th>authorc</th>\n",
       "      <th>book</th>\n",
       "      <th>book2</th>\n",
       "      <th>book4</th>\n",
       "      <th>fiction</th>\n",
       "      <th>fictional</th>\n",
       "      <th>mystery</th>\n",
       "      <th>non</th>\n",
       "      <th>novel</th>\n",
       "      <th>story</th>\n",
       "      <th>thrilling</th>\n",
       "      <th>work</th>\n",
       "      <th>wrote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adventure  authora  authorb  authorc  book  book2  book4  fiction  \\\n",
       "0          1        0        0        0     1      0      0        0   \n",
       "1          0        0        1        0     0      1      0        1   \n",
       "2          0        1        0        0     1      0      0        0   \n",
       "3          0        0        0        1     0      0      1        0   \n",
       "\n",
       "   fictional  mystery  non  novel  story  thrilling  work  wrote  \n",
       "0          0        0    0      0      0          1     0      0  \n",
       "1          0        0    1      0      0          0     1      0  \n",
       "2          1        0    0      0      1          0     0      0  \n",
       "3          0        1    0      1      0          0     0      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply bag-of-words representation\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "bow_matrix = vectorizer.fit_transform(df_advanced['Text'])\n",
    "\n",
    "# Convert the bag-of-words matrix to a DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c33870-65ef-46e0-b024-f3a1e10fe0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': 4,\n",
       " 'thrilling': 13,\n",
       " 'adventure': 0,\n",
       " 'book2': 5,\n",
       " 'non': 10,\n",
       " 'fiction': 7,\n",
       " 'work': 14,\n",
       " 'authorb': 2,\n",
       " 'fictional': 8,\n",
       " 'story': 12,\n",
       " 'authora': 1,\n",
       " 'authorc': 3,\n",
       " 'wrote': 15,\n",
       " 'mystery': 9,\n",
       " 'novel': 11,\n",
       " 'book4': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6bb8f-ee7e-46e6-880c-c8edefe04c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103df1ea-2df0-4d46-9de6-1b7be1982027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>adventure</th>\n",
       "      <th>authora</th>\n",
       "      <th>authorb</th>\n",
       "      <th>authorc</th>\n",
       "      <th>book</th>\n",
       "      <th>book2</th>\n",
       "      <th>book4</th>\n",
       "      <th>fiction</th>\n",
       "      <th>fictional</th>\n",
       "      <th>mystery</th>\n",
       "      <th>non</th>\n",
       "      <th>novel</th>\n",
       "      <th>story</th>\n",
       "      <th>thrilling</th>\n",
       "      <th>work</th>\n",
       "      <th>wrote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the first book about a thrilling adven...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book2 is a non-fiction work by AuthorB.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The third book is a fictional story by AuthorA.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AuthorC wrote a mystery novel in Book4.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  adventure  authora  \\\n",
       "0  This is the first book about a thrilling adven...          1        0   \n",
       "1            Book2 is a non-fiction work by AuthorB.          0        0   \n",
       "2    The third book is a fictional story by AuthorA.          0        1   \n",
       "3            AuthorC wrote a mystery novel in Book4.          0        0   \n",
       "\n",
       "   authorb  authorc  book  book2  book4  fiction  fictional  mystery  non  \\\n",
       "0        0        0     1      0      0        0          0        0    0   \n",
       "1        1        0     0      1      0        1          0        0    1   \n",
       "2        0        0     1      0      0        0          1        0    0   \n",
       "3        0        1     0      0      1        0          0        1    0   \n",
       "\n",
       "   novel  story  thrilling  work  wrote  \n",
       "0      0      0          1     0      0  \n",
       "1      0      0          0     1      0  \n",
       "2      0      1          0     0      0  \n",
       "3      1      0          0     0      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_advanced = pd.concat([df_advanced, bow_df], axis=1)\n",
    "\n",
    "result_df_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b6bd4-4f5e-4647-b8fc-d0def4cded3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c43df1-06ad-43b8-8887-b7471391ca01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bb8dc-770d-40a4-b8b0-ad2867fabc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bb8e56c-9984-42d4-af83-667a5797d3c6",
   "metadata": {},
   "source": [
    "## g. Creating N-grams\n",
    "- **What are n-grams?** \n",
    "    - A sequence of n words, can be bigram, trigram,....\n",
    "- **Why to use n-grams?** \n",
    "    - Capture contextual information (`good food` carries more meaning than just `good` and `food` when observed independently)\n",
    "    - Applications of N-grams:\n",
    "        - Sentence Completion\n",
    "        - Auto Spell Check and correction\n",
    "        - Auto Grammer Check and correction\n",
    "    - Is there a perfect value of n?\n",
    "        - Different types of n-grams are suitable for different types of applications. You should try different n-grams on your data in order to confidently conclude which one works the best among all for your text analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3d32b-7b9d-419c-99fe-4d0df2ea7c47",
   "metadata": {},
   "source": [
    "- **How to create n-grams?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f28689-47e1-4c10-aab4-5200a48a72ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object bigrams at 0x000002CF2D3778B0>\n",
      "('Allama', 'Iqbal')\n",
      "('Iqbal', 'was')\n",
      "('was', 'a')\n",
      "('a', 'visionary')\n",
      "('visionary', 'philosopher')\n",
      "('philosopher', 'and')\n",
      "('and', 'politician')\n",
      "('politician', '.')\n",
      "('.', 'Thank')\n",
      "('Thank', 'you')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "mystr = \"Allama Iqbal was a visionary philosopher and politician. Thank you\"\n",
    "tokens = nltk.tokenize.word_tokenize(mystr)\n",
    "bgs = nltk.bigrams(tokens)\n",
    "print(bgs)\n",
    "for grams in bgs:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c6b2d-c2b7-43ea-a079-975c50b9e61a",
   "metadata": {},
   "source": [
    ">- The formula to calculate the count of n-grams in a document is: **`X - N + 1`**, where `X` is the number of words in a given document and `N` is the number of words in n-gram\n",
    "\\begin{equation}\n",
    "    \\text{Count of N-grams} \\hspace{0.5cm} = \\hspace{0.5cm} 11 - 2 + 1 \\hspace{0.5cm} = \\hspace{0.5cm} 10\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15223d51-ec8a-439e-9afa-cc7713800dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Allama', 'Iqbal', 'was')\n",
      "('Iqbal', 'was', 'a')\n",
      "('was', 'a', 'visionary')\n",
      "('a', 'visionary', 'philosopher')\n",
      "('visionary', 'philosopher', 'and')\n",
      "('philosopher', 'and', 'politician')\n",
      "('and', 'politician', '.')\n",
      "('politician', '.', 'Thank')\n",
      "('.', 'Thank', 'you')\n"
     ]
    }
   ],
   "source": [
    "tgs = nltk.trigrams(tokens)\n",
    "for grams in tgs:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0e7f5-6feb-4762-bb05-a300605598ae",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\text{Count of N-grams} \\hspace{0.5cm} = \\hspace{0.5cm} 11 - 3 + 1 \\hspace{0.5cm} = \\hspace{0.5cm} 9\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ea5a6b2-4e14-4c73-9422-ce33021fc298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Allama', 'Iqbal', 'was', 'a')\n",
      "('Iqbal', 'was', 'a', 'visionary')\n",
      "('was', 'a', 'visionary', 'philosopher')\n",
      "('a', 'visionary', 'philosopher', 'and')\n",
      "('visionary', 'philosopher', 'and', 'politician')\n",
      "('philosopher', 'and', 'politician', '.')\n",
      "('and', 'politician', '.', 'Thank')\n",
      "('politician', '.', 'Thank', 'you')\n"
     ]
    }
   ],
   "source": [
    "ngrams = nltk.ngrams(tokens, 4)\n",
    "for grams in ngrams:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24d9c6-cf43-49d5-ae9c-249cae01a3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3b793-453a-4ada-a445-7df00a0bbc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eba9c09-3525-417e-8981-634666f7e1ab",
   "metadata": {},
   "source": [
    "## N-Grams in Bag of Words (BoW)\n",
    "\n",
    "- **Definition:**\n",
    "  - N-Grams extend the BoW representation by considering sequences of 'n' consecutive words as a single feature.\n",
    "  - Unigrams (1-grams) are single words, bigrams (2-grams) are pairs of consecutive words, trigrams (3-grams) are triplets, and so on.\n",
    "\n",
    "- **Enhancements:**\n",
    "  - **Contextual Information:** Captures the context and relationship between adjacent words.\n",
    "  - **Increased Complexity:** Larger 'n' introduces more features, leading to a richer representation.\n",
    "\n",
    "- **Use Cases:**\n",
    "  - Useful in tasks where word order matters, such as language modeling and certain types of text analysis.\n",
    "  - Provides more nuanced information for understanding the meaning of phrases.\n",
    "\n",
    "- **Implementation:**\n",
    "  - Supported in libraries like scikit-learn through the `ngram_range` parameter in `CountVectorizer`.\n",
    "\n",
    "- **Considerations:**\n",
    "  - Larger 'n' increases the dimensionality of the feature space, which may impact computational efficiency.\n",
    "  - Finding the right balance between granularity and complexity is crucial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d625b5-7212-4066-be58-a9a5cfd45013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ab65b5-b1b2-4a23-8bbe-98943ceaf63c",
   "metadata": {},
   "source": [
    "### N-Grams in Bag of Words (BoW) Example\r\n",
    "\r\n",
    "Consider a corpus with three documents:\r\n",
    "\r\n",
    "1. Document 1: \"Muhammad Sheraz is a Student of Data Science.\"\r\n",
    "2. Document 2: \"He is Learning Natural Language Processing.\"\r\n",
    "3. Document 3: \"He is very good in Machine Learning.\"\r\n",
    "\r\n",
    "#### Step 1: Tokenization and N-Gram Formation\r\n",
    "\r\n",
    "- Unique unigrams and bigrams across all documents:\r\n",
    "  - {Muhammad, Sheraz, is, a, Student, of, Data, Science, He, Learning, Natural, Language, Processing, very, good, in, Machine, Muhammad Sheraz, Sheraz is, is a, a Student, Student of, of Data, Data Science, He is, is Learning, Learning Natural, Natural Language, Language Processing, He is, is very, very good, good in, in Machine, Machine Learning}\r\n",
    "\r\n",
    "#### Step 2: Create Vocabulary\r\n",
    "\r\n",
    "- Assign an index to each unique n-gram:\r\n",
    "  - Vocabulary: {Muhammad: 0, Sheraz: 1, is: 2, a: 3, Student: 4, of: 5, Data: 6, Science: 7, He: 8, Learning: 9, Natural: 10, Language: 11, Processing: 12, very: 13, good: 14, in: 15, Machine: 16, Muhammad Sheraz: 17, Sheraz is: 18, is a: 19, a Student: 20, Student of: 21, of Data: 22, Data Science: 23, He is: 24, is Learning: 25, Learning Natural: 26, Natural Language: 27, Language Processing: 28, He is very: 29, is very good: 30, very good in: 31, good in Machine: 32, in Machine Learning: 33}\r\n",
    "\r\n",
    "#### Step 3: Document-Term Matrix (DTM) for N-Grams\r\n",
    "\r\n",
    "- Represent each document as a vector of n-gram frequencies based on the vocabulary:\r\n",
    "\r\n",
    "| Document | Muhammad | Sheraz | is | a | Student | of | Data | Science | He | Learning | Natural | Language | Processing | very | good | in | Machine | Muhammad Sheraz | Sheraz is | is a | a Student | Student of | of Data | Data Science | He is | is Learning | Learning Natural | Natural Language | Language Processing | He is very | is very good | very good in | good in Machine | in Machine Learning |\r\n",
    "|----------|----------|--------|----|---|---------|----|------|---------|----|----------|---------|----------|------------|------|------|----|---------|-----------------|-----------|-------|------------|-------------|----------|--------------|--------|--------------|-----------------|------------------|-------------------|-------------|---------------|--------------|-----------------|---------------------|\r\n",
    "| 1        | 1        | 1      | 1  | 1 | 1       | 1  | 1    | 1       | 0  | 0        | 0       | 0        | 0          | 0    | 0    | 0  | 0       | 0               | 0         | 0     | 0          | 0           | 0        | 0            | 0      | 0            | 0               | 0                | 0                 | 0           | 0             | 0            | 0               | 0                   |\r\n",
    "| 2        | 0        | 0      | 1  | 0 | 0       | 0  | 0    | 0       | 1  | 1        | 1       | 1        | 1          | 0    | 0    | 0  | 0       | 0               | 0         | 0     | 0          | 0           | 0        | 0            | 1      | 1            | 1               | 1                | 1                 | 0           | 0             | 0            | 0               | 0                   |\r\n",
    "| 3        | 0        | 0      | 1  | 0 | 0       | 0  | 0    | 0       | 1  | 0        | 0       | 0        | 0          | 1    | 1    | 1  | 1       | 0               | 0         | 0     | 0          | 0           | 0        | 0            | 1      | 0            | 0               | 0                | 0                 | 1           | 1             | 1            | 1               | 1                   |\r\n",
    "\r\n",
    "The Document-Term Matrix (DTM) for N-Grams captures the frequency of each n-gram in each document, forming the basis of the Bag of Words (BoW) representation with N-Grams.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235da910-a58d-44e4-8181-59fd077da347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11728ab2-7d2f-4254-bac9-6573c42a9a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Muhammad Sheraz is a Student of Data Science.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is Learning Natural Language Processing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is very good in Machine Learning.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text  Output\n",
       "0  \"Muhammad Sheraz is a Student of Data Science.\"       1\n",
       "1      He is Learning Natural Language Processing.       0\n",
       "2             He is very good in Machine Learning.       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a sample dataframe\n",
    "data = {'Text': ['\"Muhammad Sheraz is a Student of Data Science.\"',\n",
    "                 'He is Learning Natural Language Processing.',\n",
    "                 'He is very good in Machine Learning.'],\n",
    "        'Output': [1, 0, 1]}  # Adding a binary output column\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02617bc1-0746-4015-adce-f862654c317f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "      <th>data</th>\n",
       "      <th>data science</th>\n",
       "      <th>good</th>\n",
       "      <th>good in</th>\n",
       "      <th>good in machine</th>\n",
       "      <th>he</th>\n",
       "      <th>he is</th>\n",
       "      <th>he is learning</th>\n",
       "      <th>...</th>\n",
       "      <th>science</th>\n",
       "      <th>sheraz</th>\n",
       "      <th>sheraz is</th>\n",
       "      <th>sheraz is student</th>\n",
       "      <th>student</th>\n",
       "      <th>student of</th>\n",
       "      <th>student of data</th>\n",
       "      <th>very</th>\n",
       "      <th>very good</th>\n",
       "      <th>very good in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Muhammad Sheraz is a Student of Data Science.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is Learning Natural Language Processing.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is very good in Machine Learning.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text  Output  data  \\\n",
       "0  \"Muhammad Sheraz is a Student of Data Science.\"       1     1   \n",
       "1      He is Learning Natural Language Processing.       0     0   \n",
       "2             He is very good in Machine Learning.       1     0   \n",
       "\n",
       "   data science  good  good in  good in machine  he  he is  he is learning  \\\n",
       "0             1     0        0                0   0      0               0   \n",
       "1             0     0        0                0   1      1               1   \n",
       "2             0     1        1                1   1      1               0   \n",
       "\n",
       "   ...  science  sheraz  sheraz is  sheraz is student  student  student of  \\\n",
       "0  ...        1       1          1                  1        1           1   \n",
       "1  ...        0       0          0                  0        0           0   \n",
       "2  ...        0       0          0                  0        0           0   \n",
       "\n",
       "   student of data  very  very good  very good in  \n",
       "0                1     0          0             0  \n",
       "1                0     0          0             0  \n",
       "2                0     1          1             1  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply N-Grams using CountVectorizer\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))  # This specifies using unigrams and bigrams\n",
    "ngram_matrix = ngram_vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Convert the N-Grams matrix to a DataFrame\n",
    "ngram_df = pd.DataFrame(ngram_matrix.toarray(), columns=ngram_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the N-Grams DataFrame with the original dataframe\n",
    "result_df = pd.concat([df, ngram_df], axis=1)\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eb23d29-dbaf-4ef1-891a-37eabf3ae2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'muhammad': 26,\n",
       " 'sheraz': 37,\n",
       " 'is': 12,\n",
       " 'student': 40,\n",
       " 'of': 32,\n",
       " 'data': 0,\n",
       " 'science': 36,\n",
       " 'muhammad sheraz': 27,\n",
       " 'sheraz is': 38,\n",
       " 'is student': 15,\n",
       " 'student of': 41,\n",
       " 'of data': 33,\n",
       " 'data science': 1,\n",
       " 'muhammad sheraz is': 28,\n",
       " 'sheraz is student': 39,\n",
       " 'is student of': 16,\n",
       " 'student of data': 42,\n",
       " 'of data science': 34,\n",
       " 'he': 5,\n",
       " 'learning': 21,\n",
       " 'natural': 29,\n",
       " 'language': 19,\n",
       " 'processing': 35,\n",
       " 'he is': 6,\n",
       " 'is learning': 13,\n",
       " 'learning natural': 22,\n",
       " 'natural language': 30,\n",
       " 'language processing': 20,\n",
       " 'he is learning': 7,\n",
       " 'is learning natural': 14,\n",
       " 'learning natural language': 23,\n",
       " 'natural language processing': 31,\n",
       " 'very': 43,\n",
       " 'good': 2,\n",
       " 'in': 9,\n",
       " 'machine': 24,\n",
       " 'is very': 17,\n",
       " 'very good': 44,\n",
       " 'good in': 3,\n",
       " 'in machine': 10,\n",
       " 'machine learning': 25,\n",
       " 'he is very': 8,\n",
       " 'is very good': 18,\n",
       " 'very good in': 45,\n",
       " 'good in machine': 4,\n",
       " 'in machine learning': 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333032a-1c95-4fcf-95d3-c3a9e472132c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11786628-7ed0-417c-b33c-1d783e1fab37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a23751-89d7-4cc4-8426-9b8a4121b682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0e06a-5d72-4d13-80b2-d867b35a42d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0bace-c462-456d-84a7-c27b26a329b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd0fdb2-e279-4dee-a9bd-759a2a48f92c",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency-Inverse Document Frequency)\r\n",
    "\r\n",
    "- **Definition:**\r\n",
    "  - TF-IDF is a numerical statistic that reflects the importance of a word in a document relative to a collection of documents.\r\n",
    "  - It balances the frequency of a word in a document (Term Frequency - TF) with its rarity across documents (Inverse Document Frequency - IDF).\r\n",
    "\r\n",
    "- **Components:**\r\n",
    "  - **Term Frequency (TF):**\r\n",
    "    - Measures how often a term appears in a document.\r\n",
    "    - Calculated as the number of occurrences of a term divided by the total number of terms in the document.\r\n",
    "\r\n",
    "  - **Inverse Document Frequency (IDF):**\r\n",
    "    - Measures how unique or rare a term is across all documents.\r\n",
    "    - Calculated as the logarithm of the total number of documents divided by the number of documents containing the term.\r\n",
    "\r\n",
    "- **Formula:**\r\n",
    "  - TF-IDF = TF * IDF\r\n",
    "\r\n",
    "- **Key Characteristics:**\r\n",
    "  - Words with high TF-IDF scores are important in a specific document but not common across all documents.\r\n",
    "  - Common words receive lower scores, emphasizing the uniqueness of terms.\r\n",
    "\r\n",
    "- **Pros:**\r\n",
    "  - Captures the importance of terms in the context of a document and a corpus.\r\n",
    "  - Penalizes common words and highlights distinctive terms.\r\n",
    "\r\n",
    "- **Cons:**\r\n",
    "  - Complexity increases with a larger corpus.\r\n",
    "  - Requires careful consideration of parameter tuning.\r\n",
    "\r\n",
    "- **Use Cases:**\r\n",
    "  - Document retrieval and ranking.\r\n",
    "  - Keyword extraction.\r\n",
    "  - Text mining and clustering.\r\n",
    "\r\n",
    "- **Libraries:**\r\n",
    "  - Implemented in scikit-leary(), columns=tfidf_vectorizer.get_feature_names_out())\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a8a0a-2bf3-4dec-b051-75ba5f99ba9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8827874d-a866-416d-b5b0-5033f1d16b01",
   "metadata": {},
   "source": [
    "- ### Steps to Calculate TF-IDF\r\n",
    "    \r\n",
    "    - **Step 1: Compute Term Frequency (TF)**\r\n",
    "        - Term Frequency (TF) is calculated for each term in each document. It represents the frequency of a term in a document relative to the total number of terms in that document.\r\n",
    "        \r\n",
    "    - **Step 2: Compute Inverse Document Frequency (IDF)**\r\n",
    "        - Inverse Document Frequency (IDF) measures the importance of a term in the entire corpus. It is computed by taking the logarithm of the ratio of the total number of documents to the number of documents containing the term.\r\n",
    "    \r\n",
    "    - **Step 3: Compute TF-IDF**\r\n",
    "        - TF-IDF (Term Frequency-Inverse Document Frequency) is the product of TF and IDF. It represents the importance of a term in a document relative to its importance in the entire corpus.\r\n",
    "\r\n",
    "The TF-IDF representation captures the importance of terms in each document, emphasizing the uniqueness of terms across the entire corpus.\r\n",
    "s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8420b-ff38-4f04-90b4-0b0f857d1777",
   "metadata": {},
   "source": [
    "<img src='images/tdidf1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c4cbe-a1f6-4651-b870-8768ce003ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67243cc6-a808-4eea-a901-37816c10bd30",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Consider a corpus with three documents:\n",
    "\n",
    "1. Document 1: \"Muhammad Sheraz is a Student of Data Science.\"\n",
    "2. Document 2: \"He is Learning Natural Language Processing.\"\n",
    "3. Document 3: \"He is very good in Machine Learning.\"\n",
    "\n",
    "\n",
    "### Term Frequency (TF) Table\n",
    "\n",
    "| Term        | Document 1 | Document 2 | Document 3 |\n",
    "|-------------|------------|------------|------------|\n",
    "| Muhammad    | 1/8        | 0          | 0          |\n",
    "| Sheraz      | 1/8        | 0          | 0          |\n",
    "| is          | 1/8        | 1/8        | 1/6        |\n",
    "| a           | 1/8        | 0          | 0          |\n",
    "| Student     | 1/8        | 0          | 0          |\n",
    "| of          | 1/8        | 0          | 0          |\n",
    "| Data        | 1/8        | 0          | 0          |\n",
    "| Science     | 1/8        | 0          | 0          |\n",
    "| He          | 0          | 1/8        | 1/6        |\n",
    "| Learning    | 0          | 1/8        | 0          |\n",
    "| Natural     | 0          | 1/8        | 0          |\n",
    "| Language    | 0          | 1/8        | 0          |\n",
    "| Processing  | 0          | 1/8        | 0          |\n",
    "| very        | 0          | 0          | 1/6        |\n",
    "| good        | 0          | 0          | 1/6        |\n",
    "| in          | 0          | 0          | 1/6        |\n",
    "| Machine     | 0          | 0          | 1/6        |\n",
    "| Learning    | 0          | 0          | 0          |\n",
    "\n",
    "### Inverse Document Frequency (IDF) Table\n",
    "\n",
    "| Term        | IDF          |\n",
    "|-------------|--------------|\n",
    "| Muhammad    | 0.477        |\n",
    "| Sheraz      | 0.477        |\n",
    "| is          | 0            |\n",
    "| a           | 0.477        |\n",
    "| Student     | 0.477        |\n",
    "| of          | 0.477        |\n",
    "| Data        | 0.477        |\n",
    "| Science     | 0.477        |\n",
    "| He          | 0            |\n",
    "| Learning    | 0            |\n",
    "| Natural     | 0            |\n",
    "| Language    | 0            |\n",
    "| Processing  | 0            |\n",
    "| very        | 0            |\n",
    "| good        | 0            |\n",
    "| in          | 0            |\n",
    "| Machine     | 0            |\n",
    "\n",
    "### TF-IDF Table\n",
    "\n",
    "| Term        | Document 1 | Document 2 | Document 3 |\n",
    "|-------------|------------|------------|------------|\n",
    "| Muhammad    | 0.059      | 0          | 0          |\n",
    "| Sheraz      | 0.059      | 0          | 0          |\n",
    "| is          | 0          | 0          | 0          |\n",
    "| a           | 0.059      | 0          | 0          |\n",
    "| Student     | 0.059      | 0          | 0          |\n",
    "| of          | 0.059      | 0          | 0          |\n",
    "| Data        | 0.059      | 0          | 0          |\n",
    "| Science     | 0.059      | 0          | 0          |\n",
    "| He          | 0          | 0          | 0          |\n",
    "| Learning    | 0          | 0          | 0          |\n",
    "| Natural     | 0          | 0          | 0          |\n",
    "| Language    | 0          | 0          | 0          |\n",
    "| Processing  | 0          | 0          | 0          |\n",
    "| very        | 0          | 0          | 0.080      |\n",
    "| good        | 0          | 0          | 0.080      |\n",
    "| in          | 0          | 0          | 0.080      |\n",
    "| Machine     | 0          | 0          | 0.080      |\n",
    "| Learning    | 0          | 0          | 0          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355a85a-059d-40fe-b5f7-96bc7785d6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d3a7c-6891-4eb1-a698-c85471c70721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784867da-daa3-4f1b-afd1-1a132e1c610d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6bd708-aeed-4102-bcaf-675108862d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>good</th>\n",
       "      <th>he</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>muhammad</th>\n",
       "      <th>natural</th>\n",
       "      <th>of</th>\n",
       "      <th>processing</th>\n",
       "      <th>science</th>\n",
       "      <th>sheraz</th>\n",
       "      <th>student</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278245</td>\n",
       "      <td>0.47111</td>\n",
       "      <td>0.358291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.47111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.47111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426184</td>\n",
       "      <td>0.324124</td>\n",
       "      <td>0.426184</td>\n",
       "      <td>0.251711</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.324124</td>\n",
       "      <td>0.426184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data      good        he        in        is  language  learning  \\\n",
       "0  0.396875  0.000000  0.000000  0.000000  0.234400   0.00000  0.000000   \n",
       "1  0.000000  0.000000  0.358291  0.000000  0.278245   0.47111  0.358291   \n",
       "2  0.000000  0.426184  0.324124  0.426184  0.251711   0.00000  0.324124   \n",
       "\n",
       "    machine  muhammad  natural        of  processing   science    sheraz  \\\n",
       "0  0.000000  0.396875  0.00000  0.396875     0.00000  0.396875  0.396875   \n",
       "1  0.000000  0.000000  0.47111  0.000000     0.47111  0.000000  0.000000   \n",
       "2  0.426184  0.000000  0.00000  0.000000     0.00000  0.000000  0.000000   \n",
       "\n",
       "    student      very  \n",
       "0  0.396875  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.426184  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "# Sample documents\n",
    "documents = [\"Muhammad Sheraz is a Student of Data Science.\",\n",
    "                 'He is Learning Natural Language Processing.',\n",
    "                'He is very good in Machine Learning.']\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense array for easier manipulation\n",
    "dense_matrix = tfidf_matrix.todense()\n",
    "\n",
    "# Display the TF-IDF values in a readable format\n",
    "print(\"TF-IDF Values:\")\n",
    "pd.DataFrame(dense_matrix,columns=feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0296db-e0c8-435b-ae31-4eb5cbe5c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Names (Terms):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['data', 'good', 'he', 'in', 'is', 'language', 'learning',\n",
       "       'machine', 'muhammad', 'natural', 'of', 'processing', 'science',\n",
       "       'sheraz', 'student', 'very'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature names (terms)\n",
    "print(\"\\nFeature Names (Terms):\")\n",
    "feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73c6aaa8-9af4-4863-a5f0-765d58410776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                                        Document\n",
      "0  Muhammad Sheraz is a Student of Data Science.\n",
      "1    He is Learning Natural Language Processing.\n",
      "2           He is very good in Machine Learning.\n",
      "\n",
      "TF-IDF DataFrame:\n",
      "       data      good        he        in        is  language  learning  \\\n",
      "0  0.396875  0.000000  0.000000  0.000000  0.234400   0.00000  0.000000   \n",
      "1  0.000000  0.000000  0.358291  0.000000  0.278245   0.47111  0.358291   \n",
      "2  0.000000  0.426184  0.324124  0.426184  0.251711   0.00000  0.324124   \n",
      "\n",
      "    machine  muhammad  natural        of  processing   science    sheraz  \\\n",
      "0  0.000000  0.396875  0.00000  0.396875     0.00000  0.396875  0.396875   \n",
      "1  0.000000  0.000000  0.47111  0.000000     0.47111  0.000000  0.000000   \n",
      "2  0.426184  0.000000  0.00000  0.000000     0.00000  0.000000  0.000000   \n",
      "\n",
      "    student      very  \n",
      "0  0.396875  0.000000  \n",
      "1  0.000000  0.000000  \n",
      "2  0.000000  0.426184  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample text data\n",
    "data = {\n",
    "    'Document':  [\"Muhammad Sheraz is a Student of Data Science.\",\n",
    "                 'He is Learning Natural Language Processing.',\n",
    "                'He is very good in Machine Learning.']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Document'])\n",
    "\n",
    "# Convert TF-IDF matrix to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Display TF-IDF DataFrame\n",
    "print(\"\\nTF-IDF DataFrame:\")\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0184f-00cd-41bf-9d0d-ba8dfb45459e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c7682-f8ad-4f0b-94b1-78dbde9d27d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
